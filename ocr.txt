技术：
1.文字方向检测 使用VGG16的一个四分类算法（0， 90， 180， 270）， 小角度检测使用(estimate_skew_angle)
2.用yolo检测出含有文本框的区域text_proposals(图像输入固定压缩到608*608）， 框的宽度固定8， 高度11~283一共9个anchor是， 框的高度跟文字高度overlap超过一定值算正样本
3.text_proposals 通过文本线构造法进行同行合并（文本线构造法就是左右搜索3个框， 看高度的overlap大于一定值就在一起）
根据文本碎片框及其得分，图像尺寸，使用文本线构造法获得文本行及其得分。步骤：
将所有的碎片预测框，按左上点x坐标进行归类，定义graph,graph大小 n*n  n是碎片预测框的数量，遍历碎片预测框，根据当前索引，先往右找满足条件的配对框，再往左找满足条件的配对框（需两两相互配对），返回Graph(graph)，
删除得分较低的proposal，proposal按得分排序，对proposal做nms，根据预测的碎片框，确定每一行的碎片框（碎片框配对），根据每一行的碎片框，计算每个文本行四个角的坐标及每行得分使用得分，
图像宽高进行文本行合并，按一定条件过滤合并后的文本行
网络结构：
　　1.尺寸为(1, 3, 600, 900)的图片经过vgg_base提取特征，得到尺寸为(1, 512, 37, 56)， 再经过一层卷积后尺寸为(1, 512*9, 37, 56)

　　2. 尺寸为(1, 512*9, 37, 56)的特征图经过RNN，输出尺寸为(1, 256, 37, 56),  再经过一层卷积后尺寸为(1, 512, 37, 56)

　　3尺寸为(1, 512, 37, 56)的特征图，分别经过loc和score两个分支卷积，经过loc分支得到(1, 40, 37, 56)，这里的通道数40表示10个anchor，每个anchor包括(center_x, centert_y, w, h); 经过score分支得到(1, 20, 37, 56)，20表示10个anchor，每个anchor包括文本区域和背景两个类别
CTPN的anchor共设置了10中比例的anchor，这些anchor的宽度都为16， 高度从11一直到283。之所以将anchor的宽度设置为16，是因为CTPN网络将600*900的图片提取特征后，最后输出的特征图尺寸为37*56，缩小了16倍，特征图的感受野为16，即特征图上一个像素点对应原始图片上一个16*16的区域。
CTPN采用了Fast-Rcnn的RPN网路一样的样本分配规则，即根据anchor和gt_box的IOU，挑选出256个anchor作为样本给RPN网络学习。需要注意的是挑选的anchor样本数量，原始Fast-Rcnn中挑选出256个样本，正负样本各一半，对于CTPN，原始文字标注框需要切割成宽度为16的小框，样本数会很多，所以可以根据自己数据的特点，自己设置挑选anchor样本的总数。这里还是以挑选256个anchor为例，anchor挑选流程如下：
	1. 去掉anchor中坐标超出图片边界的(图片为600*900)
	2. 计算所有anchor和gt_box的IOU，和gt_box具有最大IOU的anchor为正样本(无论是否满足IOU>0.7)，剩余的anchor, IOU>0.7的为正样本，0<IOU<0.3的为负样本
	3. 挑选出256个样本，正负样本各128个。（若正样本不够128个时，有多少取多少，若正本超过128个，随机选取128个正样本，多余的标注未忽略样本；负样本一般会多余128个，随机选取128个负样本，多余的标注未忽略样本）
	(最后会出现两种情况，一是正负样本各128个，总共256个样本；二是正样本少于128个(如50个)，负样本128个，总样本少于256个)

4.同行的框的中心拟合一条直线， 然后通过xmin, xmax 再加上直线参数获取框的四个点（带有旋转性质的）boxes，对boxes以y值进行排序， 相当于将文本行从上到下进行排序
5.根据boxes分行一个一个输入CRNN， 根据box旋转裁剪图像， 进入CNN前，图像压缩为高度32，输出大小为（batch, w宽度，512），因为高度固定为32，经过cnn中5次下采样之后特征图的高度为1， 接下来CNN的输出要输入到双向LSTM，LSTM输出的维度是w, 也就是对应于原图每8个像素就有一个预测， 因为横向只下采样了3次，也就是相当于每一个proposal都会有一个预测， 这样肯定会重复的预测， 所以只返回跟前一个proposal不同的预测
CRNN是一种卷积循环神经网络结构，用于解决基于图像的序列识别问题，特别是场景文字识别问题。CRNN网络实现了不定长验证结合CNN和RNN网络结构，使用双向LSTM循环网络进行时序训练，并在最后引入CTC损失函数来实现端对端的不定长序列识别。
网络结构包含三部分，从下到上依次为：
（1）卷积层。作用是从输入图像中提取特征序列。
（2）循环层。作用是预测从卷积层获取的特征序列的标签（真实值）分布。
（3）转录层。作用是把从循环层获取的标签分布通过去重整合等操作转换成最终的识别结果。
CRNN卷积层由标准的CNN模型中的卷积层和最大池化层组成，自动提取出输入图像的特征序列。与普通CNN网络不同的是，CRNN在训练之前，先把输入图像缩放到相同高度（图像宽度维持原样）。
CRNN的循环层由一个双向LSTM循环神经网络构成，预测特征序列中的每一个特征向量的标签分布（真实结果的概率列表），循环层的误差被反向传播，最后会转换成特征序列，再把特征序列反馈到卷积层。LSTM（长短期记忆网络）则是一种特殊结构的RNN，用于解决RNN的长期依赖问题，普通RNN会出现“梯度消失”或“梯度爆炸”的问题，不能获取更多上下文信息，所以 CRNN 中使用的是 LSTM，允许捕获长距离依赖。LSTM单元由输入门、遗忘门和输出门组成。
转录层是将LSTM网络预测的特征序列的所有可能的结果进行整合，转换为最终结果的过程。在双向LSTM网络的最后连接上一个CTC模型，做 到端对端的识别。CTC模型（Connectionist temporal classification）联接时间分类，CTC可以执行端到端的训练，不要求训练数据对齐和一一标注，直接输出不定长的序列结果。CTC一般连接在RNN网络的最后一层用于序列学习和训练。对于一段长度为T的序列来说，每个样本点t（t远大于T）在RNN网络的最后一层都会输出一个softmax向量，表示该样本点的预测概率，所有样本点的这些概率传输给CTC模型后，输出最可能的标签，再经过去除空格（blank）和去重操作，就可以得到最终的序列标签。


困难：
	
当字典（dict）中包含的字符较少时，容易收敛。训练时字典较大，但训练样本中实际出现的字符种类较少，同样容易收敛，当字典较大时，训练样本中实际出现的字符种类繁杂，训练样本的样本容量增大有利于提升精度。然而训练样本的样本容量过于大时，容易出现梯度爆炸情况。


解决方案：
此时应该减小学习率。学习率降低能够避免nan值出现。


困难：
图片校正后同行文字可能倾斜导致文本解析混乱
解决方案：
通过修改水平系数校正

困难：
训练样本的样本容量小，精度低。
解决方案：
对图像进行旋转和不同尺度的缩放，达到增强，增加样本量的作用

困难：
病例识别中提取药品名称时出现漏检。
解决方案：
采用模糊匹配，大于一定阈值的认为是正样本。

困难：
部署困哪
解决方案：
将服务打包到docker镜像，只需拉取docker镜像，启动容器即可。

困难：
多用户同时访问http服务，导致识别响应慢或者无法响应。
解决方案：
采用多线程，一个线程单独将一定时间内用户数据以及线程id收入队列，模型一次识别batch_size大小数据，处理完后返回给用户。

